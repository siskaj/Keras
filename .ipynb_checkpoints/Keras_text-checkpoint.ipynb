{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "            \n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in enumerate(sample.split()):\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The': 1,\n",
       " 'ate': 8,\n",
       " 'cat': 2,\n",
       " 'dog': 7,\n",
       " 'homework.': 10,\n",
       " 'mat.': 6,\n",
       " 'my': 9,\n",
       " 'on': 4,\n",
       " 'sat': 3,\n",
       " 'the': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable  # All printable ASCII characters.\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s - loss: 0.6561 - acc: 0.6485 - val_loss: 0.5907 - val_acc: 0.7144\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.5189 - acc: 0.7595 - val_loss: 0.5117 - val_acc: 0.7366\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.4512 - acc: 0.7933 - val_loss: 0.4949 - val_acc: 0.7470\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.4190 - acc: 0.8069 - val_loss: 0.4905 - val_acc: 0.7536\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.3965 - acc: 0.8198 - val_loss: 0.4914 - val_acc: 0.7572\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s - loss: 0.3784 - acc: 0.8311 - val_loss: 0.4953 - val_acc: 0.7594\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s - loss: 0.3624 - acc: 0.8418 - val_loss: 0.5004 - val_acc: 0.7574\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.3474 - acc: 0.8483 - val_loss: 0.5058 - val_acc: 0.7572\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.3330 - acc: 0.8583 - val_loss: 0.5122 - val_acc: 0.7528\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 0s - loss: 0.3194 - acc: 0.8667 - val_loss: 0.5183 - val_acc: 0.7552\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = '/Users/jsiska3/Downloads/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# %%debug\n",
    "# import pdb\n",
    "# from pdb import set_trace as bp\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100\n",
    "training_samples = 200\n",
    "validation_samples = 10000\n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples : training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = '/Users/jsiska3/Downloads/glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s - loss: 2.0324 - acc: 0.5150 - val_loss: 0.7076 - val_acc: 0.5285\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s - loss: 0.5201 - acc: 0.7500 - val_loss: 0.9912 - val_acc: 0.5025\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s - loss: 0.3905 - acc: 0.8550 - val_loss: 0.6943 - val_acc: 0.5593\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s - loss: 0.3745 - acc: 0.8250 - val_loss: 1.7490 - val_acc: 0.4999\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s - loss: 0.2896 - acc: 0.8950 - val_loss: 0.7016 - val_acc: 0.5728\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s - loss: 0.1165 - acc: 1.0000 - val_loss: 0.8405 - val_acc: 0.5298\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s - loss: 0.1259 - acc: 0.9950 - val_loss: 0.9231 - val_acc: 0.5248\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s - loss: 0.0628 - acc: 1.0000 - val_loss: 1.0257 - val_acc: 0.5201\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s - loss: 0.0734 - acc: 1.0000 - val_loss: 1.7048 - val_acc: 0.5077\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s - loss: 0.2037 - acc: 0.9150 - val_loss: 0.7563 - val_acc: 0.5665\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history= model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.hy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130d8c908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130e438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'bo')\n",
    "plt.plot(epochs, val_acc, 'b+')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo')\n",
    "plt.plot(epochs, val_loss, 'b+')\n",
    "plt.title('Training and validation loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
